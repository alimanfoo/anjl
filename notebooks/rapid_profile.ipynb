{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae893ef8-3f7f-474e-a176-5012121e1f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> **Note:** loading the `profila` extension can impact Numba's performance. Make sure to disable it once you're done profiling!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext profila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6600780-d0bd-42db-8db8-a13dfe078214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcaff1fc-e130-4661-b6d2-61320969b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "from scipy.spatial.distance import squareform\n",
    "import numpy as np\n",
    "import anjl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5245947-65cd-4817-b606-d36f6f21279e",
   "metadata": {},
   "source": [
    "## Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b6a001e-6e46-4c56-8c37-33ef5693d6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 19., 19., ..., 22., 28., 12.],\n",
       "       [19.,  0., 20., ..., 21., 25., 15.],\n",
       "       [19., 20.,  0., ..., 21., 23., 17.],\n",
       "       ...,\n",
       "       [22., 21., 21., ...,  0., 22., 18.],\n",
       "       [28., 25., 23., ..., 22.,  0., 22.],\n",
       "       [12., 15., 17., ..., 18., 22.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large = zarr.load(\"../data/large/dist.zarr.zip\")\n",
    "large_D = squareform(large)\n",
    "shuffle = np.random.choice(large_D.shape[0], size=1500, replace=False)\n",
    "large_D_shuffled = large_D.take(shuffle, axis=0).take(shuffle, axis=1)\n",
    "large_D_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c13257-4c9c-4310-a45b-79058918bea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aliman/.cache/pypoetry/virtualenvs/anjl-Dyqcv450-py3.10/lib/python3.10/site-packages/numba/core/lowering.py:112: NumbaDebugInfoWarning: Could not find source for function: <function __numba_array_expr_0x760e889aa290 at 0x760e8896da20>. Debug line information may be inaccurate.\n",
      "  warnings.warn(NumbaDebugInfoWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.56 s, sys: 33.5 ms, total: 2.6 s\n",
      "Wall time: 2.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "large_Z = anjl.canonical_nj(large_D_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0889365c-223e-439e-896b-b1e6fd3707bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aliman/github/alimanfoo/anjl/anjl/_rapid.py:266: NumbaDebugInfoWarning: Could not find source for function: <function __numba_array_expr_0x760e8894c340 at 0x760e88a104c0>. Debug line information may be inaccurate.\n",
      "  u_max = _rapid_update(\n",
      "/home/aliman/.cache/pypoetry/virtualenvs/anjl-Dyqcv450-py3.10/lib/python3.10/site-packages/numba/core/lowering.py:112: NumbaDebugInfoWarning: Could not find source for function: <function __numba_array_expr_0x760e88cc2fe0 at 0x760e88991990>. Debug line information may be inaccurate.\n",
      "  warnings.warn(NumbaDebugInfoWarning(msg))\n",
      "/home/aliman/.cache/pypoetry/virtualenvs/anjl-Dyqcv450-py3.10/lib/python3.10/site-packages/numba/core/lowering.py:112: NumbaDebugInfoWarning: Could not find source for function: <function __numba_array_expr_0x760e873f0b20 at 0x760e88c81000>. Debug line information may be inaccurate.\n",
      "  warnings.warn(NumbaDebugInfoWarning(msg))\n",
      "/home/aliman/github/alimanfoo/anjl/anjl/_rapid.py:266: NumbaDebugInfoWarning: Could not find source for function: <function __numba_array_expr_0x760e88bdfcd0 at 0x760e88a12710>. Debug line information may be inaccurate.\n",
      "  u_max = _rapid_update(\n",
      "/home/aliman/.cache/pypoetry/virtualenvs/anjl-Dyqcv450-py3.10/lib/python3.10/site-packages/numba/core/lowering.py:112: NumbaDebugInfoWarning: Could not find source for function: <function __numba_array_expr_0x760e88ade4a0 at 0x760e88ca1ab0>. Debug line information may be inaccurate.\n",
      "  warnings.warn(NumbaDebugInfoWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 39.3 ms, total: 11.5 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "large_Z = anjl.rapid_nj(large_D_shuffled, gc=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c44b72-6d4a-496c-8b98-3a0ac39ae722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%snakeviz\n",
    "# anjl.canonical_nj(large_D_shuffled)\n",
    "# anjl.rapid_nj(large_D_shuffled, gc=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74987835-ee0a-403b-86a8-db2859f88cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%snakeviz\n",
    "# anjl.rapid_nj(large_D_shuffled, gc=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "619a9949-e825-48c3-9de6-7e62d2b026ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.7700000e+02, 8.4600000e+02, 0.0000000e+00, 0.0000000e+00,\n",
       "        2.0000000e+00],\n",
       "       [1.2670000e+03, 1.5000000e+03, 0.0000000e+00, 0.0000000e+00,\n",
       "        3.0000000e+00],\n",
       "       [6.2000000e+01, 1.5010000e+03, 2.6737968e-03, 9.9732620e-01,\n",
       "        4.0000000e+00],\n",
       "       ...,\n",
       "       [2.9800000e+03, 2.9910000e+03, 2.2690046e-01, 1.1441791e-01,\n",
       "        1.3700000e+02],\n",
       "       [2.9950000e+03, 2.9960000e+03, 8.2687199e-02, 4.4224620e-02,\n",
       "        1.4600000e+03],\n",
       "       [2.9490000e+03, 2.9970000e+03, 3.0133229e-01, 3.0133229e-01,\n",
       "        1.5000000e+03]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/markdown": [
       "**Elapsed:** 23.558 seconds\n",
       "\n",
       "**Total samples:** 1985 (14.7% non-Numba samples, 0.0% bad samples)\n",
       "\n",
       "/home/aliman/github/alimanfoo/anjl/anjl/_rapid.py (lines 2 to 481):\n",
       "\n",
       "```\n",
       "  0.1% | from collections.abc import Mapping\n",
       "       | import numpy as np\n",
       "       | import numba\n",
       "       | import time\n",
       "       | \n",
       "       | \n",
       "       | def rapid_nj(\n",
       "       |     D: np.ndarray,\n",
       "       |     disallow_negative_distances: bool = True,\n",
       "       |     progress: Callable | None = None,\n",
       "       |     progress_options: Mapping = {},\n",
       "       |     diagnostics=False,\n",
       "       |     gc=100,\n",
       "       |     # contiguate=False,\n",
       "       | ) -> np.ndarray:\n",
       "       |     \"\"\"TODO\"\"\"\n",
       "       | \n",
       "       |     # Make a copy of distance matrix D because we will overwrite it during the\n",
       "       |     # algorithm.\n",
       "       |     D = np.array(D, copy=True, order=\"C\", dtype=np.float32)\n",
       "       | \n",
       "       |     # Initialize the \"divergence\" array, containing sum of distances to other nodes.\n",
       "       |     U = np.sum(D, axis=1, dtype=np.float32)\n",
       "       |     u_max = U.max()\n",
       "       | \n",
       "       |     # Set diagonal to inf to avoid self comparison sorting first.\n",
       "       |     for i in range(D.shape[0]):\n",
       "       |         D[i, i] = np.inf\n",
       "       | \n",
       "       |     # Obtain node identifiers to sort the distance matrix row-wise.\n",
       "       |     nodes_sorted = np.argsort(D, axis=1)\n",
       "       |     assert D.shape == nodes_sorted.shape\n",
       "       | \n",
       "       |     # Make another copy of the distance matrix sorted.\n",
       "       |     D_sorted = np.take_along_axis(D, nodes_sorted, axis=1)\n",
       "       | \n",
       "       |     # Number of original observations.\n",
       "       |     n_original = D.shape[0]\n",
       "       | \n",
       "       |     # Expected number of new (internal) nodes that will be created.\n",
       "       |     n_internal = n_original - 1\n",
       "       | \n",
       "       |     # Total number of nodes in the tree, including internal nodes.\n",
       "       |     n_nodes = n_original + n_internal\n",
       "       | \n",
       "       |     # Map row indices to node IDs.\n",
       "       |     index_to_id = np.arange(n_original)\n",
       "       | \n",
       "       |     # Map node IDs to row indices.\n",
       "       |     id_to_index = np.full(shape=n_nodes, fill_value=-1)\n",
       "       |     id_to_index[:n_original] = np.arange(n_original)\n",
       "       | \n",
       "       |     # Initialise output. This is similar to the output that scipy hierarchical\n",
       "       |     # clustering functions return, where each row contains data for one internal node\n",
       "       |     # in the tree, except that each row here contains:\n",
       "       |     # - left child node ID\n",
       "       |     # - right child node ID\n",
       "       |     # - distance to left child node\n",
       "       |     # - distance to right child node\n",
       "       |     # - total number of leaves\n",
       "       |     Z = np.zeros(shape=(n_internal, 5), dtype=np.float32)\n",
       "       | \n",
       "       |     # Keep track of which nodes have been clustered and are now \"obsolete\". N.B., this\n",
       "       |     # is different from canonical implementation because we index here by node ID.\n",
       "       |     clustered = np.zeros(shape=n_nodes - 1, dtype=bool)\n",
       "       | \n",
       "       |     # Convenience to also keep track of which rows are no longer in use.\n",
       "       |     obsolete = np.zeros(shape=n_original, dtype=bool)\n",
       "       | \n",
       "       |     # Support wrapping the iterator in a progress bar.\n",
       "       |     iterator = range(n_internal)\n",
       "       |     if progress:\n",
       "       |         iterator = progress(iterator, **progress_options)\n",
       "       | \n",
       "       |     # Record iteration timings.\n",
       "       |     timings = []\n",
       "       |     searches = []\n",
       "       |     visits = []\n",
       "       | \n",
       "       |     # Begin iterating.\n",
       "       |     for iteration in iterator:\n",
       "       |         # print(\"\")\n",
       "       |         # print(\"iteration\", iteration)\n",
       "       |         # print(\"D\\n\", D)\n",
       "       |         # print(\"D_sorted\\n\", D_sorted)\n",
       "       |         # print(\"nodes_sorted\\n\", nodes_sorted)\n",
       "       |         # print(\"U\", U)\n",
       "       |         # print(\"index_to_id\", index_to_id)\n",
       "       |         # print(\"id_to_index\", id_to_index)\n",
       "       | \n",
       "       |         # Number of nodes remaining in this iteration.\n",
       "       |         n_remaining = n_original - iteration\n",
       "       | \n",
       "       |         # Garbage collection.\n",
       "       |         if gc and iteration > 0 and iteration % gc == 0:\n",
       "       |             nodes_sorted, D_sorted = _rapid_gc(\n",
       "       |                 nodes_sorted=nodes_sorted,\n",
       "       |                 D_sorted=D_sorted,\n",
       "       |                 index_to_id=index_to_id,\n",
       "       |                 clustered=clustered,\n",
       "       |                 obsolete=obsolete,\n",
       "       |                 n_remaining=n_remaining,\n",
       "       |                 # contiguate=contiguate,\n",
       "       |             )\n",
       "       | \n",
       "       |         before = time.time()\n",
       "       | \n",
       "       |         # Perform one iteration of the neighbour-joining algorithm.\n",
       "       |         u_max, searched, visited = _rapid_iteration(\n",
       "       |             iteration=iteration,\n",
       "       |             D=D,\n",
       "       |             D_sorted=D_sorted,\n",
       "       |             U=U,\n",
       "       |             nodes_sorted=nodes_sorted,\n",
       "       |             index_to_id=index_to_id,\n",
       "       |             id_to_index=id_to_index,\n",
       "       |             clustered=clustered,\n",
       "       |             obsolete=obsolete,\n",
       "       |             Z=Z,\n",
       "       |             n_original=n_original,\n",
       "       |             disallow_negative_distances=disallow_negative_distances,\n",
       "       |             u_max=u_max,\n",
       "       |         )\n",
       "       | \n",
       "       |         duration = time.time() - before\n",
       "       |         timings.append(duration)\n",
       "       |         searches.append(searched)\n",
       "       |         visits.append(visited)\n",
       "       | \n",
       "       |     if diagnostics:\n",
       "       |         return Z, np.array(timings), np.array(searches), np.array(visits)\n",
       "       | \n",
       "       |     return Z\n",
       "       | \n",
       "       | \n",
       "       | @numba.njit\n",
       "       | def _rapid_gc(\n",
       "       |     nodes_sorted: np.ndarray,\n",
       "       |     D_sorted: np.ndarray,\n",
       "       |     index_to_id: np.ndarray,\n",
       "       |     clustered: np.ndarray,\n",
       "       |     obsolete: np.ndarray,\n",
       "       |     n_remaining: int,\n",
       "       |     # contiguate: bool,\n",
       "       | ):\n",
       "       |     for i in range(nodes_sorted.shape[0]):\n",
       "       |         if obsolete[i]:\n",
       "       |             continue\n",
       "  0.4% |         id_i = index_to_id[i]\n",
       "       |         j_new = 0\n",
       "  1.0% |         for j in range(nodes_sorted.shape[1]):\n",
       "       |             id_j = nodes_sorted[i, j]\n",
       "  2.2% |             if clustered[id_j]:\n",
       "       |                 continue\n",
       "       |             if id_i == id_j:\n",
       "       |                 continue\n",
       "  1.2% |             nodes_sorted[i, j_new] = id_j\n",
       "  0.8% |             D_sorted[i, j_new] = D_sorted[i, j]\n",
       "  0.3% |             j_new += 1\n",
       "       |     nodes_sorted = nodes_sorted[:, :n_remaining]\n",
       "       |     D_sorted = D_sorted[:, :n_remaining]\n",
       "       |     # if contiguate:\n",
       "       |     #     nodes_sorted = nodes_sorted.copy()\n",
       "       |     #     D_sorted = D_sorted.copy()\n",
       "       |     return nodes_sorted, D_sorted\n",
       "       | \n",
       "       | \n",
       "       | @numba.njit\n",
       "       | def _rapid_iteration(\n",
       "       |     iteration: int,\n",
       "       |     D: np.ndarray,\n",
       "       |     D_sorted: np.ndarray,\n",
       "       |     U: np.ndarray,\n",
       "       |     nodes_sorted: np.ndarray,\n",
       "       |     index_to_id: np.ndarray,\n",
       "       |     id_to_index: np.ndarray,\n",
       "       |     clustered: np.ndarray,\n",
       "       |     obsolete: np.ndarray,\n",
       "       |     Z: np.ndarray,\n",
       "       |     n_original: int,\n",
       "       |     disallow_negative_distances: bool,\n",
       "       |     u_max: np.float32,\n",
       "       | ) -> np.float32:\n",
       "       |     # This will be the identifier for the new node to be created in this iteration.\n",
       "       |     node = iteration + n_original\n",
       "       | \n",
       "       |     # Number of nodes remaining in this iteration.\n",
       "       |     n_remaining = n_original - iteration\n",
       "       | \n",
       "       |     if n_remaining > 2:\n",
       "       |         # Search for the closest pair of nodes to join.\n",
       "       |         i_min, j_min, searched, visited = _rapid_search(\n",
       "       |             D_sorted=D_sorted,\n",
       "       |             U=U,\n",
       "       |             nodes_sorted=nodes_sorted,\n",
       "       |             clustered=clustered,\n",
       "       |             obsolete=obsolete,\n",
       "       |             index_to_id=index_to_id,\n",
       "       |             id_to_index=id_to_index,\n",
       "       |             n_remaining=n_remaining,\n",
       "       |             u_max=u_max,\n",
       "       |         )\n",
       "       |         assert i_min >= 0\n",
       "       |         assert j_min >= 0\n",
       "       |         assert i_min != j_min\n",
       "       | \n",
       "       |         # Get IDs for the nodes to be joined.\n",
       "       |         child_i = index_to_id[i_min]\n",
       "       |         child_j = index_to_id[j_min]\n",
       "       | \n",
       "       |         # Calculate distances to the new internal node.\n",
       "       |         d_ij = D[i_min, j_min]\n",
       "       |         d_i = 0.5 * (d_ij + (1 / (n_remaining - 2)) * (U[i_min] - U[j_min]))\n",
       "       |         d_j = 0.5 * (d_ij + (1 / (n_remaining - 2)) * (U[j_min] - U[i_min]))\n",
       "       | \n",
       "       |     else:\n",
       "       |         # Termination. Join the two remaining nodes, placing the final node at the\n",
       "       |         # midpoint.\n",
       "       |         child_i, child_j = np.nonzero(~clustered)[0]\n",
       "       |         i_min = id_to_index[child_i]\n",
       "       |         j_min = id_to_index[child_j]\n",
       "       |         d_ij = D[i_min, j_min]\n",
       "       |         d_i = d_ij / 2\n",
       "       |         d_j = d_ij / 2\n",
       "       |         searched = 0\n",
       "       |         visited = 0\n",
       "       | \n",
       "       |     # Sanity checks.\n",
       "       |     assert child_i >= 0\n",
       "       |     assert child_j >= 0\n",
       "       |     assert child_i != child_j\n",
       "       | \n",
       "       |     # print(\"i_min\", i_min, \"j_min\", j_min, \"child_i\", child_i, \"child_j\", child_j)\n",
       "       | \n",
       "       |     # Handle possibility of negative distances.\n",
       "       |     if disallow_negative_distances:\n",
       "       |         d_i = max(0, d_i)\n",
       "       |         d_j = max(0, d_j)\n",
       "       | \n",
       "       |     # Stabilise ordering for easier comparisons.\n",
       "       |     if child_i > child_j:\n",
       "       |         child_i, child_j = child_j, child_i\n",
       "       |         i_min, j_min = j_min, i_min\n",
       "       |         d_i, d_j = d_j, d_i\n",
       "       | \n",
       "       |     # Get number of leaves.\n",
       "       |     if child_i < n_original:\n",
       "       |         leaves_i = 1\n",
       "       |     else:\n",
       "       |         leaves_i = Z[child_i - n_original, 4]\n",
       "       |     if child_j < n_original:\n",
       "       |         leaves_j = 1\n",
       "       |     else:\n",
       "       |         leaves_j = Z[child_j - n_original, 4]\n",
       "       | \n",
       "       |     # Store new node data.\n",
       "       |     Z[iteration, 0] = child_i\n",
       "       |     Z[iteration, 1] = child_j\n",
       "       |     Z[iteration, 2] = d_i\n",
       "       |     Z[iteration, 3] = d_j\n",
       "       |     Z[iteration, 4] = leaves_i + leaves_j\n",
       "       | \n",
       "       |     if n_remaining > 2:\n",
       "       |         # Update data structures.\n",
       "  0.1% |         u_max = _rapid_update(\n",
       "       |             D=D,\n",
       "       |             D_sorted=D_sorted,\n",
       "       |             U=U,\n",
       "       |             nodes_sorted=nodes_sorted,\n",
       "       |             index_to_id=index_to_id,\n",
       "       |             id_to_index=id_to_index,\n",
       "       |             clustered=clustered,\n",
       "       |             obsolete=obsolete,\n",
       "       |             node=node,\n",
       "       |             child_i=child_i,\n",
       "       |             child_j=child_j,\n",
       "       |             i_min=i_min,\n",
       "       |             j_min=j_min,\n",
       "       |             d_ij=d_ij,\n",
       "       |         )\n",
       "       | \n",
       "       |     return u_max, searched, visited\n",
       "       | \n",
       "       | \n",
       "       | @numba.njit\n",
       "       | def _rapid_search(\n",
       "       |     D_sorted: np.ndarray,\n",
       "       |     U: np.ndarray,\n",
       "       |     nodes_sorted: np.ndarray,\n",
       "       |     clustered: np.ndarray,\n",
       "       |     obsolete: np.ndarray,\n",
       "       |     index_to_id: np.ndarray,\n",
       "       |     id_to_index: np.ndarray,\n",
       "       |     n_remaining: int,\n",
       "       |     u_max: np.float32,\n",
       "       | ) -> tuple[int, int, int]:\n",
       "       |     # Initialize working variables.\n",
       "       |     q_min = numba.float32(np.inf)\n",
       "       |     threshold = numba.float32(np.inf)\n",
       "       |     i_min = -1\n",
       "       |     j_min = -1\n",
       "       |     searched = 0\n",
       "       |     visited = 0\n",
       "       |     coefficient = numba.float32(n_remaining - 2)\n",
       "       |     m = nodes_sorted.shape[0]\n",
       "       |     n = nodes_sorted.shape[1]\n",
       "  0.3% |     assert m == D_sorted.shape[0]\n",
       "       |     assert n == D_sorted.shape[1]\n",
       "       | \n",
       "       |     # indices_available = np.nonzero(~obsolete)[0]\n",
       "       |     # # np.random.shuffle(indices_available)\n",
       "       |     # for i in indices_available:\n",
       "       | \n",
       "       |     # Search all values up to threshold.\n",
       "  0.2% |     for i in range(m):\n",
       "       |         # Skip if row is no longer in use.\n",
       "  0.3% |         if obsolete[i]:\n",
       "       |             continue\n",
       "       | \n",
       "       |         # Obtain identifier for this row.\n",
       "       |         node_i = index_to_id[i]\n",
       "       | \n",
       "       |         # Obtain divergence for node corresponding to this row.\n",
       "  0.4% |         u_i = U[i]\n",
       "       | \n",
       "       |         # Search the row up to threshold.\n",
       "  8.3% |         for s in range(n):\n",
       "  2.2% |             visited += 1\n",
       "       | \n",
       "       |             # Obtain node identifier for the current item.\n",
       "  1.1% |             node_j = nodes_sorted[i, s]\n",
       "       | \n",
       "       |             # Break at end of nodes.\n",
       "  5.4% |             if node_j < 0:\n",
       "       |                 break\n",
       "       | \n",
       "       |             # Skip if this node is already clustered.\n",
       "  5.8% |             if clustered[node_j]:\n",
       "       |                 continue\n",
       "       | \n",
       "       |             # TODO needed?\n",
       "       |             if node_i == node_j:\n",
       "       |                 continue\n",
       "       | \n",
       "       |             # Access distance.\n",
       "       |             d = D_sorted[i, s]\n",
       "       | \n",
       "       |             # Partially calculate q.\n",
       "  5.2% |             q_partial = coefficient * d - u_i\n",
       "       | \n",
       "       |             # Limit search. Because the row is sorted, if we are already above this\n",
       "       |             # threshold then we know there is no need to search remaining nodes in the\n",
       "       |             # row.\n",
       " 10.7% |             if q_partial > threshold:\n",
       "       |                 break\n",
       "       | \n",
       "       |             # Fully calculate q.\n",
       "  2.2% |             j = id_to_index[node_j]\n",
       "  5.2% |             u_j = U[j]\n",
       " 11.7% |             q = q_partial - u_j\n",
       "  0.4% |             searched += 1\n",
       "       | \n",
       "  5.2% |             if q < q_min:\n",
       "       |                 q_min = q\n",
       "  0.3% |                 threshold = q_min + u_max\n",
       "       |                 i_min = i\n",
       "       |                 j_min = j\n",
       "       | \n",
       "       |     return i_min, j_min, searched, visited\n",
       "       | \n",
       "       | \n",
       "       | @numba.njit\n",
       "       | def _rapid_update(\n",
       "       |     D: np.ndarray,\n",
       "       |     D_sorted: np.ndarray,\n",
       "       |     U: np.ndarray,\n",
       "       |     nodes_sorted: np.ndarray,\n",
       "       |     index_to_id: np.ndarray,\n",
       "       |     id_to_index: np.ndarray,\n",
       "       |     clustered: np.ndarray,\n",
       "       |     obsolete: np.ndarray,\n",
       "       |     node: int,\n",
       "       |     child_i: int,\n",
       "       |     child_j: int,\n",
       "       |     i_min: int,\n",
       "       |     j_min: int,\n",
       "       |     d_ij: float,\n",
       "       | ) -> np.float32:\n",
       "       |     # Update data structures. Here we obsolete the row corresponding to the node at\n",
       "       |     # j_min, and we reuse the row at i_min for the new node.\n",
       "       |     clustered[child_i] = True\n",
       "       |     clustered[child_j] = True\n",
       "       |     # index_to_id[j_min] = -1\n",
       "       |     # id_to_index[child_i] = -1\n",
       "       |     # id_to_index[child_j] = -1\n",
       "       | \n",
       "       |     # Assign the new node to row at i_min.\n",
       "       |     index_to_id[i_min] = node\n",
       "       |     id_to_index[node] = i_min\n",
       "       | \n",
       "       |     # Obsolete the data corresponding to the node at j_min.\n",
       "       |     obsolete[j_min] = True\n",
       "       | \n",
       "       |     # Subtract out the distances for the nodes that have just been joined.\n",
       "       |     for i in range(U.shape[0]):\n",
       "  0.1% |         if i != i_min and i != j_min and not obsolete[i]:\n",
       "  1.0% |             U[i] -= D[i, i_min]\n",
       "  0.4% |             U[i] -= D[i, j_min]\n",
       "       | \n",
       "       |     # Initialize divergence for the new node.\n",
       "       |     u_new = np.float32(0)\n",
       "       | \n",
       "       |     # Find new max.\n",
       "       |     u_max = np.float32(0)\n",
       "       | \n",
       "       |     # Update distances and divergence.\n",
       "  0.1% |     for k in range(D.shape[0]):\n",
       "  0.1% |         if obsolete[k]:\n",
       "       |             continue\n",
       "       | \n",
       "       |         if k == i_min or k == j_min:\n",
       "       |             continue\n",
       "       | \n",
       "       |         # Distance from k to the new node.\n",
       "       |         d_ik = D[k, i_min]\n",
       "       |         d_jk = D[k, j_min]\n",
       "  0.4% |         d_k = 0.5 * (d_ik + d_jk - d_ij)\n",
       "  0.1% |         D[i_min, k] = d_k\n",
       "       |         D[k, i_min] = d_k\n",
       "       |         u_k = U[k] + d_k\n",
       "  0.1% |         U[k] = u_k\n",
       "       | \n",
       "       |         # Record new max.\n",
       "       |         if u_k > u_max:\n",
       "       |             u_max = u_k\n",
       "       | \n",
       "       |         # Accumulate divergence for the new node.\n",
       "       |         u_new += d_k\n",
       "       | \n",
       "       |         # Distance from k to the obsolete node.\n",
       "       |         D[k, j_min] = np.inf\n",
       "       | \n",
       "       |     # Store divergence for the new node.\n",
       "       |     U[i_min] = u_new\n",
       "       | \n",
       "       |     # Record new max.\n",
       "       |     if u_new > u_max:\n",
       "       |         u_max = u_new\n",
       "       | \n",
       "       |     # Finish up obsoleting data for j_min.\n",
       "       |     # U[j_min] = np.nan\n",
       "       |     # D[j_min, :] = np.inf\n",
       "       |     # D[:, j_min] = np.inf\n",
       "       |     # D_sorted[j_min] = np.inf\n",
       "       |     # nodes_sorted[j_min] = -1\n",
       "       | \n",
       "       |     # First cut down to just the active nodes.\n",
       "  0.5% |     active = ~obsolete\n",
       "  0.5% |     distances_new = D[i_min, active]\n",
       "  0.7% |     nodes_active = index_to_id[active]\n",
       "       | \n",
       "       |     # Now sort the new distances.\n",
       "       |     indices_sorted = np.argsort(distances_new)\n",
       "  0.2% |     nodes_sorted_new = nodes_active[indices_sorted]\n",
       "  0.2% |     distances_sorted_new = distances_new[indices_sorted]\n",
       "       | \n",
       "       |     # # Update the sorted distances and indices for the new node.\n",
       "       |     # distances_new = D[i_min]\n",
       "       |     # sorted_indices_new = np.argsort(distances_new)\n",
       "       |     # sorted_ids_new = np.take(index_to_id, sorted_indices_new)\n",
       "       | \n",
       "       |     # # Remove any clustered nodes.\n",
       "       |     # clustered_new = np.take(clustered, sorted_ids_new)\n",
       "       |     # sorted_ids_new = sorted_ids_new[~clustered_new]\n",
       "       | \n",
       "       |     p = nodes_sorted_new.shape[0]\n",
       "       |     assert p == distances_new.shape[0]\n",
       "       |     nodes_sorted[i_min, :p] = nodes_sorted_new\n",
       "  0.1% |     nodes_sorted[i_min, p:] = -1\n",
       "  0.1% |     D_sorted[i_min, :p] = distances_sorted_new\n",
       "```\n",
       "\n",
       "/home/aliman/.cache/pypoetry/virtualenvs/anjl-Dyqcv450-py3.10/lib/python3.10/site-packages/numba/misc/quicksort.py (lines 43 to 197):\n",
       "\n",
       "```\n",
       "  0.1% |                 return np.arange(A.size)\n",
       "       | \n",
       "       |         @wrap\n",
       "  0.4% |         def GET(A, idx_or_val):\n",
       "  1.9% |             return A[idx_or_val]\n",
       "       | \n",
       "       |     else:\n",
       "       |         @wrap\n",
       "       |         def make_res(A):\n",
       "       |             return A\n",
       "       | \n",
       "       |         @wrap\n",
       "       |         def GET(A, idx_or_val):\n",
       "       |             return idx_or_val\n",
       "       | \n",
       "       |     def default_lt(a, b):\n",
       "       |         \"\"\"\n",
       "       |         Trivial comparison function between two keys.\n",
       "       |         \"\"\"\n",
       "       |         return a < b\n",
       "       | \n",
       "       |     LT = wrap(lt if lt is not None else default_lt)\n",
       "       | \n",
       "       |     @wrap\n",
       "       |     def insertion_sort(A, R, low, high):\n",
       "       |         \"\"\"\n",
       "       |         Insertion sort A[low:high + 1]. Note the inclusive bounds.\n",
       "  0.1% |         \"\"\"\n",
       "       |         assert low >= 0\n",
       "       |         if high <= low:\n",
       "       |             return\n",
       "       | \n",
       "       |         for i in range(low + 1, high + 1):\n",
       "       |             k = R[i]\n",
       "  0.2% |             v = GET(A, k)\n",
       "       |             # Insert v into A[low:i]\n",
       "       |             j = i\n",
       "  0.4% |             while j > low and LT(v, GET(A, R[j - 1])):\n",
       "       |                 # Make place for moving A[i] downwards\n",
       "  0.1% |                 R[j] = R[j - 1]\n",
       "       |                 j -= 1\n",
       "  0.1% |             R[j] = k\n",
       "       | \n",
       "       |     @wrap\n",
       "       |     def partition(A, R, low, high):\n",
       "       |         \"\"\"\n",
       "       |         Partition A[low:high + 1] around a chosen pivot.  The pivot's index\n",
       "       |         is returned.\n",
       "  0.2% |         \"\"\"\n",
       "       |         assert low >= 0\n",
       "       |         assert high > low\n",
       "       | \n",
       "       |         mid = (low + high) >> 1\n",
       "       |         # NOTE: the pattern of swaps below for the pivot choice and the\n",
       "       |         # partitioning gives good results (i.e. regular O(n log n))\n",
       "       |         # on sorted, reverse-sorted, and uniform arrays.  Subtle changes\n",
       "       |         # risk breaking this property.\n",
       "       | \n",
       "       |         # median of three {low, middle, high}\n",
       "  0.1% |         if LT(GET(A, R[mid]), GET(A, R[low])):\n",
       "       |             R[low], R[mid] = R[mid], R[low]\n",
       "  0.1% |         if LT(GET(A, R[high]), GET(A, R[mid])):\n",
       "       |             R[high], R[mid] = R[mid], R[high]\n",
       "       |         if LT(GET(A, R[mid]), GET(A, R[low])):\n",
       "       |             R[low], R[mid] = R[mid], R[low]\n",
       "  0.1% |         pivot = GET(A, R[mid])\n",
       "       | \n",
       "       |         # Temporarily stash the pivot at the end\n",
       "       |         R[high], R[mid] = R[mid], R[high]\n",
       "       |         i = low\n",
       "       |         j = high - 1\n",
       "       |         while True:\n",
       "  1.4% |             while i < high and LT(GET(A, R[i]), pivot):\n",
       "       |                 i += 1\n",
       "  1.5% |             while j >= low and LT(pivot, GET(A, R[j])):\n",
       "       |                 j -= 1\n",
       "       |             if i >= j:\n",
       "       |                 break\n",
       "  0.3% |             R[i], R[j] = R[j], R[i]\n",
       "  0.1% |             i += 1\n",
       "       |             j -= 1\n",
       "       |         # Put the pivot back in its final place (all items before `i`\n",
       "       |         # are smaller than the pivot, all items at/after `i` are larger)\n",
       "  0.1% |         R[i], R[high] = R[high], R[i]\n",
       "       |         return i\n",
       "       | \n",
       "       |     @wrap\n",
       "       |     def partition3(A, low, high):\n",
       "       |         \"\"\"\n",
       "       |         Three-way partition [low, high) around a chosen pivot.\n",
       "       |         A tuple (lt, gt) is returned such that:\n",
       "       |             - all elements in [low, lt) are < pivot\n",
       "       |             - all elements in [lt, gt] are == pivot\n",
       "       |             - all elements in (gt, high] are > pivot\n",
       "       |         \"\"\"\n",
       "       |         mid = (low + high) >> 1\n",
       "       |         # median of three {low, middle, high}\n",
       "       |         if LT(A[mid], A[low]):\n",
       "       |             A[low], A[mid] = A[mid], A[low]\n",
       "       |         if LT(A[high], A[mid]):\n",
       "       |             A[high], A[mid] = A[mid], A[high]\n",
       "       |         if LT(A[mid], A[low]):\n",
       "       |             A[low], A[mid] = A[mid], A[low]\n",
       "       |         pivot = A[mid]\n",
       "       | \n",
       "       |         A[low], A[mid] = A[mid], A[low]\n",
       "       |         lt = low\n",
       "       |         gt = high\n",
       "       |         i = low + 1\n",
       "       |         while i <= gt:\n",
       "       |             if LT(A[i], pivot):\n",
       "       |                 A[lt], A[i] = A[i], A[lt]\n",
       "       |                 lt += 1\n",
       "       |                 i += 1\n",
       "       |             elif LT(pivot, A[i]):\n",
       "       |                 A[gt], A[i] = A[i], A[gt]\n",
       "       |                 gt -= 1\n",
       "       |             else:\n",
       "       |                 i += 1\n",
       "       |         return lt, gt\n",
       "       | \n",
       "       |     @wrap\n",
       "       |     def run_quicksort1(A):\n",
       "       |         R = make_res(A)\n",
       "       | \n",
       "       |         if len(A) < 2:\n",
       "  0.1% |             return R\n",
       "       | \n",
       "       |         stack = [Partition(zero, zero)] * MAX_STACK\n",
       "  0.1% |         stack[0] = Partition(zero, len(A) - 1)\n",
       "       |         n = 1\n",
       "       | \n",
       "       |         while n > 0:\n",
       "       |             n -= 1\n",
       "       |             low, high = stack[n]\n",
       "       |             # Partition until it becomes more efficient to do an insertion sort\n",
       "       |             while high - low >= SMALL_QUICKSORT:\n",
       "       |                 assert n < MAX_STACK\n",
       "  0.1% |                 i = partition(A, R, low, high)\n",
       "       |                 # Push largest partition on the stack\n",
       "       |                 if high - i > i - low:\n",
       "       |                     # Right is larger\n",
       "       |                     if high > i:\n",
       "  0.1% |                         stack[n] = Partition(i + 1, high)\n",
       "       |                         n += 1\n",
       "       |                     high = i - 1\n",
       "       |                 else:\n",
       "       |                     if i > low:\n",
       "       |                         stack[n] = Partition(low, i - 1)\n",
       "       |                         n += 1\n",
       "       |                     low = i + 1\n",
       "       | \n",
       "  0.1% |             insertion_sort(A, R, low, high)\n",
       "       | \n",
       "  0.1% |         return R\n",
       "```\n",
       "\n",
       "/home/aliman/.cache/pypoetry/virtualenvs/anjl-Dyqcv450-py3.10/lib/python3.10/site-packages/numba/np/numpy_support.py (lines 739 to 739):\n",
       "\n",
       "```\n",
       "  2.8% |     return a < b or (np.isnan(b) and not np.isnan(a))\n",
       "```\n",
       "\n",
       "/home/aliman/.cache/pypoetry/virtualenvs/anjl-Dyqcv450-py3.10/lib/python3.10/site-packages/numba/np/arrayobj.py (lines 4260 to 4822):\n",
       "\n",
       "```\n",
       "  0.2% |         return intrin_alloc(allocsize, align)\n",
       "       |     return impl\n",
       "       | \n",
       "       | \n",
       "       | def _call_allocator(arrtype, size, align):\n",
       "       |     \"\"\"Trampoline to call the intrinsic used for allocation\n",
       "       |     \"\"\"\n",
       "       |     return arrtype._allocate(size, align)\n",
       "       | \n",
       "       | \n",
       "       | @intrinsic\n",
       "       | def intrin_alloc(typingctx, allocsize, align):\n",
       "       |     \"\"\"Intrinsic to call into the allocator for Array\n",
       "       |     \"\"\"\n",
       "       |     def codegen(context, builder, signature, args):\n",
       "       |         [allocsize, align] = args\n",
       "       |         meminfo = context.nrt.meminfo_alloc_aligned(builder, allocsize, align)\n",
       "       |         return meminfo\n",
       "       | \n",
       "       |     mip = types.MemInfoPointer(types.voidptr)    # return untyped pointer\n",
       "       |     sig = signature(mip, allocsize, align)\n",
       "       |     return sig, codegen\n",
       "       | \n",
       "       | \n",
       "       | def _parse_shape(context, builder, ty, val):\n",
       "       |     \"\"\"\n",
       "       |     Parse the shape argument to an array constructor.\n",
       "       |     \"\"\"\n",
       "       |     def safecast_intp(context, builder, src_t, src):\n",
       "       |         \"\"\"Cast src to intp only if value can be maintained\"\"\"\n",
       "       |         intp_t = context.get_value_type(types.intp)\n",
       "       |         intp_width = intp_t.width\n",
       "       |         intp_ir = ir.IntType(intp_width)\n",
       "       |         maxval = Constant(intp_ir, ((1 << intp_width - 1) - 1))\n",
       "       |         if src_t.width < intp_width:\n",
       "       |             res = builder.sext(src, intp_ir)\n",
       "       |         elif src_t.width >= intp_width:\n",
       "       |             is_larger = builder.icmp_signed(\">\", src, maxval)\n",
       "       |             with builder.if_then(is_larger, likely=False):\n",
       "       |                 context.call_conv.return_user_exc(\n",
       "       |                     builder, ValueError,\n",
       "       |                     (\"Cannot safely convert value to intp\",)\n",
       "       |                 )\n",
       "       |             if src_t.width > intp_width:\n",
       "       |                 res = builder.trunc(src, intp_ir)\n",
       "       |             else:\n",
       "       |                 res = src\n",
       "       |         return res\n",
       "       | \n",
       "       |     if isinstance(ty, types.Integer):\n",
       "       |         ndim = 1\n",
       "       |         passed_shapes = [context.cast(builder, val, ty, types.intp)]\n",
       "       |     else:\n",
       "       |         assert isinstance(ty, types.BaseTuple)\n",
       "       |         ndim = ty.count\n",
       "       |         passed_shapes = cgutils.unpack_tuple(builder, val, count=ndim)\n",
       "       | \n",
       "       |     shapes = []\n",
       "       |     for s in passed_shapes:\n",
       "       |         shapes.append(safecast_intp(context, builder, s.type, s))\n",
       "       | \n",
       "       |     zero = context.get_constant_generic(builder, types.intp, 0)\n",
       "       |     for dim in range(ndim):\n",
       "       |         is_neg = builder.icmp_signed('<', shapes[dim], zero)\n",
       "       |         with cgutils.if_unlikely(builder, is_neg):\n",
       "       |             context.call_conv.return_user_exc(\n",
       "       |                 builder, ValueError, (\"negative dimensions not allowed\",)\n",
       "       |             )\n",
       "       | \n",
       "       |     return shapes\n",
       "       | \n",
       "       | \n",
       "       | def _parse_empty_args(context, builder, sig, args):\n",
       "       |     \"\"\"\n",
       "       |     Parse the arguments of a np.empty(), np.zeros() or np.ones() call.\n",
       "       |     \"\"\"\n",
       "       |     arrshapetype = sig.args[0]\n",
       "       |     arrshape = args[0]\n",
       "       |     arrtype = sig.return_type\n",
       "       |     return arrtype, _parse_shape(context, builder, arrshapetype, arrshape)\n",
       "       | \n",
       "       | \n",
       "       | def _parse_empty_like_args(context, builder, sig, args):\n",
       "       |     \"\"\"\n",
       "       |     Parse the arguments of a np.empty_like(), np.zeros_like() or\n",
       "       |     np.ones_like() call.\n",
       "       |     \"\"\"\n",
       "       |     arytype = sig.args[0]\n",
       "       |     if isinstance(arytype, types.Array):\n",
       "       |         ary = make_array(arytype)(context, builder, value=args[0])\n",
       "       |         shapes = cgutils.unpack_tuple(builder, ary.shape, count=arytype.ndim)\n",
       "       |         return sig.return_type, shapes\n",
       "       |     else:\n",
       "       |         return sig.return_type, ()\n",
       "       | \n",
       "       | \n",
       "       | def _check_const_str_dtype(fname, dtype):\n",
       "       |     if isinstance(dtype, types.UnicodeType):\n",
       "       |         msg = f\"If np.{fname} dtype is a string it must be a string constant.\"\n",
       "       |         raise errors.TypingError(msg)\n",
       "       | \n",
       "       | \n",
       "       | @intrinsic\n",
       "       | def numpy_empty_nd(tyctx, ty_shape, ty_dtype, ty_retty_ref):\n",
       "       |     ty_retty = ty_retty_ref.instance_type\n",
       "       |     sig = ty_retty(ty_shape, ty_dtype, ty_retty_ref)\n",
       "       | \n",
       "       |     def codegen(cgctx, builder, sig, llargs):\n",
       "       |         arrtype, shapes = _parse_empty_args(cgctx, builder, sig, llargs)\n",
       "       |         ary = _empty_nd_impl(cgctx, builder, arrtype, shapes)\n",
       "       |         return ary._getvalue()\n",
       "       |     return sig, codegen\n",
       "       | \n",
       "       | \n",
       "       | @overload(np.empty)\n",
       "       | def ol_np_empty(shape, dtype=float):\n",
       "       |     _check_const_str_dtype(\"empty\", dtype)\n",
       "       |     if (dtype is float or\n",
       "       |         (isinstance(dtype, types.Function) and dtype.typing_key is float) or\n",
       "       |             is_nonelike(dtype)): #default\n",
       "       |         nb_dtype = types.double\n",
       "       |     else:\n",
       "       |         nb_dtype = ty_parse_dtype(dtype)\n",
       "       | \n",
       "       |     ndim = ty_parse_shape(shape)\n",
       "       |     if nb_dtype is not None and ndim is not None:\n",
       "       |         retty = types.Array(dtype=nb_dtype, ndim=ndim, layout='C')\n",
       "       | \n",
       "  0.1% |         def impl(shape, dtype=float):\n",
       "       |             return numpy_empty_nd(shape, dtype, retty)\n",
       "       |         return impl\n",
       "       |     else:\n",
       "       |         msg = f\"Cannot parse input types to function np.empty({shape}, {dtype})\"\n",
       "       |         raise errors.TypingError(msg)\n",
       "       | \n",
       "       | \n",
       "       | @intrinsic\n",
       "       | def numpy_empty_like_nd(tyctx, ty_prototype, ty_dtype, ty_retty_ref):\n",
       "       |     ty_retty = ty_retty_ref.instance_type\n",
       "       |     sig = ty_retty(ty_prototype, ty_dtype, ty_retty_ref)\n",
       "       | \n",
       "       |     def codegen(cgctx, builder, sig, llargs):\n",
       "       |         arrtype, shapes = _parse_empty_like_args(cgctx, builder, sig, llargs)\n",
       "       |         ary = _empty_nd_impl(cgctx, builder, arrtype, shapes)\n",
       "       |         return ary._getvalue()\n",
       "       |     return sig, codegen\n",
       "       | \n",
       "       | \n",
       "       | @overload(np.empty_like)\n",
       "       | def ol_np_empty_like(arr, dtype=None):\n",
       "       |     _check_const_str_dtype(\"empty_like\", dtype)\n",
       "       |     if not is_nonelike(dtype):\n",
       "       |         nb_dtype = ty_parse_dtype(dtype)\n",
       "       |     elif isinstance(arr, types.Array):\n",
       "       |         nb_dtype = arr.dtype\n",
       "       |     else:\n",
       "       |         nb_dtype = arr\n",
       "       |     if nb_dtype is not None:\n",
       "       |         if isinstance(arr, types.Array):\n",
       "       |             layout = arr.layout if arr.layout != 'A' else 'C'\n",
       "       |             retty = arr.copy(dtype=nb_dtype, layout=layout, readonly=False)\n",
       "       |         else:\n",
       "       |             retty = types.Array(nb_dtype, 0, 'C')\n",
       "       |     else:\n",
       "       |         msg = (\"Cannot parse input types to function \"\n",
       "       |                f\"np.empty_like({arr}, {dtype})\")\n",
       "       |         raise errors.TypingError(msg)\n",
       "       | \n",
       "       |     def impl(arr, dtype=None):\n",
       "       |         return numpy_empty_like_nd(arr, dtype, retty)\n",
       "       |     return impl\n",
       "       | \n",
       "       | \n",
       "       | @intrinsic\n",
       "       | def _zero_fill_array_method(tyctx, self):\n",
       "       |     sig = types.none(self)\n",
       "       | \n",
       "       |     def codegen(cgctx, builder, sig, llargs):\n",
       "       |         ary = make_array(sig.args[0])(cgctx, builder, llargs[0])\n",
       "       |         cgutils.memset(builder, ary.data, builder.mul(ary.itemsize, ary.nitems),\n",
       "       |                        0)\n",
       "       |     return sig, codegen\n",
       "       | \n",
       "       | \n",
       "       | @overload_method(types.Array, '_zero_fill')\n",
       "       | def ol_array_zero_fill(self):\n",
       "       |     \"\"\"Adds a `._zero_fill` method to zero fill an array using memset.\"\"\"\n",
       "       |     def impl(self):\n",
       "       |         _zero_fill_array_method(self)\n",
       "       |     return impl\n",
       "       | \n",
       "       | \n",
       "       | @overload(np.zeros)\n",
       "       | def ol_np_zeros(shape, dtype=float):\n",
       "       |     _check_const_str_dtype(\"zeros\", dtype)\n",
       "       | \n",
       "       |     def impl(shape, dtype=float):\n",
       "       |         arr = np.empty(shape, dtype=dtype)\n",
       "       |         arr._zero_fill()\n",
       "       |         return arr\n",
       "       |     return impl\n",
       "       | \n",
       "       | \n",
       "       | @overload(np.zeros_like)\n",
       "       | def ol_np_zeros_like(a, dtype=None):\n",
       "       |     _check_const_str_dtype(\"zeros_like\", dtype)\n",
       "       | \n",
       "       |     # NumPy uses 'a' as the arg name for the array-like\n",
       "       |     def impl(a, dtype=None):\n",
       "       |         arr = np.empty_like(a, dtype=dtype)\n",
       "       |         arr._zero_fill()\n",
       "       |         return arr\n",
       "       |     return impl\n",
       "       | \n",
       "       | \n",
       "       | @overload(np.ones_like)\n",
       "       | def ol_np_ones_like(a, dtype=None):\n",
       "       |     _check_const_str_dtype(\"ones_like\", dtype)\n",
       "       | \n",
       "       |     # NumPy uses 'a' as the arg name for the array-like\n",
       "       |     def impl(a, dtype=None):\n",
       "       |         arr = np.empty_like(a, dtype=dtype)\n",
       "       |         arr_flat = arr.flat\n",
       "       |         for idx in range(len(arr_flat)):\n",
       "       |             arr_flat[idx] = 1\n",
       "       |         return arr\n",
       "       |     return impl\n",
       "       | \n",
       "       | \n",
       "       | @overload(np.full)\n",
       "       | def impl_np_full(shape, fill_value, dtype=None):\n",
       "       |     _check_const_str_dtype(\"full\", dtype)\n",
       "       |     if not is_nonelike(dtype):\n",
       "       |         nb_dtype = ty_parse_dtype(dtype)\n",
       "       |     else:\n",
       "       |         nb_dtype = fill_value\n",
       "       | \n",
       "       |     def full(shape, fill_value, dtype=None):\n",
       "       |         arr = np.empty(shape, nb_dtype)\n",
       "       |         arr_flat = arr.flat\n",
       "       |         for idx in range(len(arr_flat)):\n",
       "       |             arr_flat[idx] = fill_value\n",
       "       |         return arr\n",
       "       |     return full\n",
       "       | \n",
       "       | \n",
       "       | @overload(np.full_like)\n",
       "       | def impl_np_full_like(a, fill_value, dtype=None):\n",
       "       |     _check_const_str_dtype(\"full_like\", dtype)\n",
       "       | \n",
       "       |     def full_like(a, fill_value, dtype=None):\n",
       "       |         arr = np.empty_like(a, dtype)\n",
       "       |         arr_flat = arr.flat\n",
       "       |         for idx in range(len(arr_flat)):\n",
       "       |             arr_flat[idx] = fill_value\n",
       "       |         return arr\n",
       "       | \n",
       "       |     return full_like\n",
       "       | \n",
       "       | \n",
       "       | @overload(np.ones)\n",
       "       | def ol_np_ones(shape, dtype=None):\n",
       "       |     # for some reason the NumPy default for dtype is None in the source but\n",
       "       |     # ends up as np.float64 by definition.\n",
       "       |     _check_const_str_dtype(\"ones\", dtype)\n",
       "       | \n",
       "       |     def impl(shape, dtype=None):\n",
       "       |         arr = np.empty(shape, dtype=dtype)\n",
       "       |         arr_flat = arr.flat\n",
       "       |         for idx in range(len(arr_flat)):\n",
       "       |             arr_flat[idx] = 1\n",
       "       |         return arr\n",
       "       |     return impl\n",
       "       | \n",
       "       | \n",
       "       | @overload(np.identity)\n",
       "       | def impl_np_identity(n, dtype=None):\n",
       "       |     _check_const_str_dtype(\"identity\", dtype)\n",
       "       |     if not is_nonelike(dtype):\n",
       "       |         nb_dtype = ty_parse_dtype(dtype)\n",
       "       |     else:\n",
       "       |         nb_dtype = types.double\n",
       "       | \n",
       "       |     def identity(n, dtype=None):\n",
       "       |         arr = np.zeros((n, n), nb_dtype)\n",
       "       |         for i in range(n):\n",
       "       |             arr[i, i] = 1\n",
       "       |         return arr\n",
       "       |     return identity\n",
       "       | \n",
       "       | \n",
       "       | def _eye_none_handler(N, M):\n",
       "       |     pass\n",
       "       | \n",
       "       | \n",
       "       | @extending.overload(_eye_none_handler)\n",
       "       | def _eye_none_handler_impl(N, M):\n",
       "       |     if isinstance(M, types.NoneType):\n",
       "       |         def impl(N, M):\n",
       "       |             return N\n",
       "       |     else:\n",
       "       |         def impl(N, M):\n",
       "       |             return M\n",
       "       |     return impl\n",
       "       | \n",
       "       | \n",
       "       | @extending.overload(np.eye)\n",
       "       | def numpy_eye(N, M=None, k=0, dtype=float):\n",
       "       | \n",
       "       |     if dtype is None or isinstance(dtype, types.NoneType):\n",
       "       |         dt = np.dtype(float)\n",
       "       |     elif isinstance(dtype, (types.DTypeSpec, types.Number)):\n",
       "       |         # dtype or instance of dtype\n",
       "       |         dt = as_dtype(getattr(dtype, 'dtype', dtype))\n",
       "       |     else:\n",
       "       |         dt = np.dtype(dtype)\n",
       "       | \n",
       "       |     def impl(N, M=None, k=0, dtype=float):\n",
       "       |         _M = _eye_none_handler(N, M)\n",
       "       |         arr = np.zeros((N, _M), dt)\n",
       "       |         if k >= 0:\n",
       "       |             d = min(N, _M - k)\n",
       "       |             for i in range(d):\n",
       "       |                 arr[i, i + k] = 1\n",
       "       |         else:\n",
       "       |             d = min(N + k, _M)\n",
       "       |             for i in range(d):\n",
       "       |                 arr[i - k, i] = 1\n",
       "       |         return arr\n",
       "       |     return impl\n",
       "       | \n",
       "       | \n",
       "       | @overload(np.diag)\n",
       "       | def impl_np_diag(v, k=0):\n",
       "       |     if not type_can_asarray(v):\n",
       "       |         raise errors.TypingError('The argument \"v\" must be array-like')\n",
       "       | \n",
       "       |     if isinstance(v, types.Array):\n",
       "       |         if v.ndim not in (1, 2):\n",
       "       |             raise errors.NumbaTypeError(\"Input must be 1- or 2-d.\")\n",
       "       | \n",
       "       |         def diag_impl(v, k=0):\n",
       "       |             if v.ndim == 1:\n",
       "       |                 s = v.shape\n",
       "       |                 n = s[0] + abs(k)\n",
       "       |                 ret = np.zeros((n, n), v.dtype)\n",
       "       |                 if k >= 0:\n",
       "       |                     for i in range(n - k):\n",
       "       |                         ret[i, k + i] = v[i]\n",
       "       |                 else:\n",
       "       |                     for i in range(n + k):\n",
       "       |                         ret[i - k, i] = v[i]\n",
       "       |                 return ret\n",
       "       |             else:  # 2-d\n",
       "       |                 rows, cols = v.shape\n",
       "       |                 if k < 0:\n",
       "       |                     rows = rows + k\n",
       "       |                 if k > 0:\n",
       "       |                     cols = cols - k\n",
       "       |                 n = max(min(rows, cols), 0)\n",
       "       |                 ret = np.empty(n, v.dtype)\n",
       "       |                 if k >= 0:\n",
       "       |                     for i in range(n):\n",
       "       |                         ret[i] = v[i, k + i]\n",
       "       |                 else:\n",
       "       |                     for i in range(n):\n",
       "       |                         ret[i] = v[i - k, i]\n",
       "       |                 return ret\n",
       "       |         return diag_impl\n",
       "       | \n",
       "       | \n",
       "       | @overload(np.indices)\n",
       "       | def numpy_indices(dimensions):\n",
       "       |     if not isinstance(dimensions, types.UniTuple):\n",
       "       |         msg = 'The argument \"dimensions\" must be a tuple of integers'\n",
       "       |         raise errors.TypingError(msg)\n",
       "       | \n",
       "       |     if not isinstance(dimensions.dtype, types.Integer):\n",
       "       |         msg = 'The argument \"dimensions\" must be a tuple of integers'\n",
       "       |         raise errors.TypingError(msg)\n",
       "       | \n",
       "       |     N = len(dimensions)\n",
       "       |     shape = (1,) * N\n",
       "       | \n",
       "       |     def impl(dimensions):\n",
       "       |         res = np.empty((N,) + dimensions, dtype=np.int64)\n",
       "       |         i = 0\n",
       "       |         for dim in dimensions:\n",
       "       |             idx = np.arange(dim, dtype=np.int64).reshape(\n",
       "       |                 tuple_setitem(shape, i, dim)\n",
       "       |             )\n",
       "       |             res[i] = idx\n",
       "       |             i += 1\n",
       "       | \n",
       "       |         return res\n",
       "       | \n",
       "       |     return impl\n",
       "       | \n",
       "       | \n",
       "       | @overload(np.diagflat)\n",
       "       | def numpy_diagflat(v, k=0):\n",
       "       |     if not type_can_asarray(v):\n",
       "       |         msg = 'The argument \"v\" must be array-like'\n",
       "       |         raise errors.TypingError(msg)\n",
       "       | \n",
       "       |     if not isinstance(k, (int, types.Integer)):\n",
       "       |         msg = 'The argument \"k\" must be an integer'\n",
       "       |         raise errors.TypingError(msg)\n",
       "       | \n",
       "       |     def impl(v, k=0):\n",
       "       |         v = np.asarray(v)\n",
       "       |         v = v.ravel()\n",
       "       |         s = len(v)\n",
       "       |         abs_k = abs(k)\n",
       "       |         n = s + abs_k\n",
       "       |         res = np.zeros((n, n), v.dtype)\n",
       "       |         i = np.maximum(0, -k)\n",
       "       |         j = np.maximum(0, k)\n",
       "       |         for t in range(s):\n",
       "       |             res[i + t, j + t] = v[t]\n",
       "       | \n",
       "       |         return res\n",
       "       | \n",
       "       |     return impl\n",
       "       | \n",
       "       | \n",
       "       | @overload(np.take)\n",
       "       | @overload_method(types.Array, 'take')\n",
       "       | def numpy_take(a, indices):\n",
       "       | \n",
       "       |     if isinstance(a, types.Array) and isinstance(indices, types.Integer):\n",
       "       |         def take_impl(a, indices):\n",
       "       |             if indices > (a.size - 1) or indices < -a.size:\n",
       "       |                 raise IndexError(\"Index out of bounds\")\n",
       "       |             return a.ravel()[indices]\n",
       "       |         return take_impl\n",
       "       | \n",
       "       |     if all(isinstance(arg, types.Array) for arg in [a, indices]):\n",
       "       |         F_order = indices.layout == 'F'\n",
       "       | \n",
       "       |         def take_impl(a, indices):\n",
       "       |             ret = np.empty(indices.size, dtype=a.dtype)\n",
       "       |             if F_order:\n",
       "       |                 walker = indices.copy()  # get C order\n",
       "       |             else:\n",
       "       |                 walker = indices\n",
       "       |             it = np.nditer(walker)\n",
       "       |             i = 0\n",
       "       |             flat = a.ravel()\n",
       "       |             for x in it:\n",
       "       |                 if x > (a.size - 1) or x < -a.size:\n",
       "       |                     raise IndexError(\"Index out of bounds\")\n",
       "       |                 ret[i] = flat[x]\n",
       "       |                 i = i + 1\n",
       "       |             return ret.reshape(indices.shape)\n",
       "       |         return take_impl\n",
       "       | \n",
       "       |     if isinstance(a, types.Array) and \\\n",
       "       |             isinstance(indices, (types.List, types.BaseTuple)):\n",
       "       |         def take_impl(a, indices):\n",
       "       |             convert = np.array(indices)\n",
       "       |             ret = np.empty(convert.size, dtype=a.dtype)\n",
       "       |             it = np.nditer(convert)\n",
       "       |             i = 0\n",
       "       |             flat = a.ravel()\n",
       "       |             for x in it:\n",
       "       |                 if x > (a.size - 1) or x < -a.size:\n",
       "       |                     raise IndexError(\"Index out of bounds\")\n",
       "       |                 ret[i] = flat[x]\n",
       "       |                 i = i + 1\n",
       "       |             return ret.reshape(convert.shape)\n",
       "       |         return take_impl\n",
       "       | \n",
       "       | \n",
       "       | def _arange_dtype(*args):\n",
       "       |     bounds = [a for a in args if not isinstance(a, types.NoneType)]\n",
       "       | \n",
       "       |     if any(isinstance(a, types.Complex) for a in bounds):\n",
       "       |         dtype = types.complex128\n",
       "       |     elif any(isinstance(a, types.Float) for a in bounds):\n",
       "       |         dtype = types.float64\n",
       "       |     else:\n",
       "       |         # `np.arange(10).dtype` is always `np.dtype(int)`, aka `np.int_`, which\n",
       "       |         # in all released versions of numpy corresponds to the C `long` type.\n",
       "       |         # Windows 64 is broken by default here because Numba (as of 0.47) does\n",
       "       |         # not differentiate between Python and NumPy integers, so a `typeof(1)`\n",
       "       |         # on w64 is `int64`, i.e. `intp`. This means an arange(<some int>) will\n",
       "       |         # be typed as arange(int64) and the following will yield int64 opposed\n",
       "       |         # to int32. Example: without a load of analysis to work out of the args\n",
       "       |         # were wrapped in NumPy int*() calls it's not possible to detect the\n",
       "       |         # difference between `np.arange(10)` and `np.arange(np.int64(10)`.\n",
       "       |         NPY_TY = getattr(types, \"int%s\" % (8 * np.dtype(int).itemsize))\n",
       "       | \n",
       "       |         # unliteral these types such that `max` works.\n",
       "       |         unliteral_bounds = [types.unliteral(x) for x in bounds]\n",
       "       |         dtype = max(unliteral_bounds + [NPY_TY,])\n",
       "       | \n",
       "       |     return dtype\n",
       "       | \n",
       "       | \n",
       "       | @overload(np.arange)\n",
       "       | def np_arange(start, / ,stop=None, step=None, dtype=None):\n",
       "       |     if isinstance(stop, types.Optional):\n",
       "       |         stop = stop.type\n",
       "       |     if isinstance(step, types.Optional):\n",
       "       |         step = step.type\n",
       "       |     if isinstance(dtype, types.Optional):\n",
       "       |         dtype = dtype.type\n",
       "       | \n",
       "       |     if stop is None:\n",
       "       |         stop = types.none\n",
       "       |     if step is None:\n",
       "       |         step = types.none\n",
       "       |     if dtype is None:\n",
       "       |         dtype = types.none\n",
       "       | \n",
       "       |     if (not isinstance(start, types.Number) or\n",
       "       |         not isinstance(stop, (types.NoneType, types.Number)) or\n",
       "       |         not isinstance(step, (types.NoneType, types.Number)) or\n",
       "       |             not isinstance(dtype, (types.NoneType, types.DTypeSpec))):\n",
       "       | \n",
       "       |         return\n",
       "       | \n",
       "       |     if isinstance(dtype, types.NoneType):\n",
       "       |         true_dtype = _arange_dtype(start, stop, step)\n",
       "       |     else:\n",
       "       |         true_dtype = dtype.dtype\n",
       "       | \n",
       "       |     use_complex = any([isinstance(x, types.Complex)\n",
       "       |                        for x in (start, stop, step)])\n",
       "       | \n",
       "       |     start_value = getattr(start, \"literal_value\", None)\n",
       "       |     stop_value = getattr(stop, \"literal_value\", None)\n",
       "       |     step_value = getattr(step, \"literal_value\", None)\n",
       "       | \n",
       "       |     def impl(start, /, stop=None, step=None, dtype=None):\n",
       "       |         # Allow for improved performance if given literal arguments.\n",
       "       |         lit_start = start_value if start_value is not None else start\n",
       "       |         lit_stop = stop_value if stop_value is not None else stop\n",
       "       |         lit_step = step_value if step_value is not None else step\n",
       "       | \n",
       "       |         _step = lit_step if lit_step is not None else 1\n",
       "       |         if lit_stop is None:\n",
       "       |             _start, _stop = 0, lit_start\n",
       "       |         else:\n",
       "       |             _start, _stop = lit_start, lit_stop\n",
       "       | \n",
       "       |         if _step == 0:\n",
       "       |             raise ValueError(\"Maximum allowed size exceeded\")\n",
       "       | \n",
       "       |         nitems_c = (_stop - _start) / _step\n",
       "       |         nitems_r = int(math.ceil(nitems_c.real))\n",
       "       | \n",
       "       |         # Binary operator needed for compiler branch pruning.\n",
       "       |         if use_complex is True:\n",
       "       |             nitems_i = int(math.ceil(nitems_c.imag))\n",
       "       |             nitems = max(min(nitems_i, nitems_r), 0)\n",
       "       |         else:\n",
       "       |             nitems = max(nitems_r, 0)\n",
       "       |         arr = np.empty(nitems, true_dtype)\n",
       "       |         val = _start\n",
       "  0.1% |         for i in range(nitems):\n",
       "  0.1% |             arr[i] = val + (i * _step)\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%profila\n",
    "anjl.rapid_nj(large_D_shuffled, gc=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df09dd4-e47b-45ab-b368-0dbc303ead9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%profila\n",
    "anjl.canonical_nj(large_D_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bb80f7-ee56-466a-88b4-f781dcc48657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
